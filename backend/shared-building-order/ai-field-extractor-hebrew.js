/**
 * AI-Powered Field Extractor using Anthropic Claude
 * Uses Claude Opus to extract Hebrew shared building order fields with high accuracy
 */

const Anthropic = require('@anthropic-ai/sdk');
const dotenv = require('dotenv');
const fs = require('fs');

dotenv.config();

class SharedBuildingAIExtractor {
  constructor(apiKey) {
    this.client = new Anthropic({
      apiKey: apiKey || process.env.ANTHROPIC_API_KEY
    });
    
    this.model = 'claude-3-5-sonnet-20241022'; // Updated model
  }

  /**
   * Step 1: Extract document structure and basic information
   * @param {string|Buffer} input - Either markdown text or PDF file path
   * @param {Object} options - Processing options {useVision: boolean}
   * @returns {Promise<Object>} - Document structure analysis
   */
  async extractDocumentStructure(input, options = {}) {
    const systemPrompt = `××ª×” ××•××—×” ×œ× ×™×ª×•×— ××¡××›×™ ×¦×• ×¨×™×©×•× ×‘×™×ª ××©×•×ª×£ ×‘×¢×‘×¨×™×ª.

××©×™××” ×¨××©×•× ×”: × ×ª×— ××ª ××‘× ×” ×”××¡××š ×•××¦× ××ª ×”××™×“×¢ ×”×‘×¡×™×¡×™.

×—×¤×© ×•××¦×:
1. ×›××” ××‘× ×™× ×™×© ×‘×¤×¨×•×™×§×˜ ×•××” ×”×›×ª×•×‘×ª ×©×œ ×›×œ ××‘× ×” ××˜×‘×œ×ª ×ª×™××•×¨ ×”×‘×™×ª
   - ×—×œ×¥ ××ª ×›×œ ×”××‘× ×™× ×¢× ×”× ×ª×•× ×™× ×”××œ××™×: ××¡×¤×¨ ××‘× ×”, ×›×ª×•×‘×ª, ×§×•××•×ª, ×•××¡×¤×¨ ×ª×ª×™ ×—×œ×§×•×ª
   - ×‘×“×•×§ ×‘×˜×‘×œ×ª "×ª×™××•×¨ ×”×‘×™×ª" - ×œ×›×œ ×©×•×¨×” ×™×© ××‘× ×” ×¢× ×›×ª×•×‘×ª
2. ×›××” ×§×•××•×ª ×™×© ×‘×›×œ ××‘× ×” (××˜×‘×œ×ª ×ª×™××•×¨ ×”×‘×™×ª)
3. ×›××” ×ª×ª×™ ×—×œ×§×•×ª ×™×© ×‘×›×œ ××‘× ×” (××”×¢××•×“×•×ª ×‘×˜×‘×œ×ª ×ª×™××•×¨ ×”×‘×™×ª)
4. ××” ×”××¡×¤×¨ ×”×›×•×œ×œ ×©×œ ×ª×ª×™ ×”×—×œ×§×•×ª:
   - ×¨××©×™×ª ×—×¤×© "×¡×”×´×› ×ª×ª×™ ×—×œ×§×•×ª" ×‘×˜×‘×œ×ª "×ª×™××•×¨ ×”×‘×™×ª" (×˜×‘×œ×” 1)
   - ×× ×œ× ×§×™×™× ×‘×˜×‘×œ×”, ××¦× ××ª ××¡×¤×¨ ×ª×ª ×”×—×œ×§×” ×”×’×‘×•×” ×‘×™×•×ª×¨ ××˜×‘×œ××•×ª "×ª×™××•×¨ ×ª×ª×™ ×—×œ×§×•×ª ×•×ª×¦××•×“×•×ª"
   - ×”×ª×¢×œ× ×××¡×¤×¨×™ ×¨×™×©×•×, ×›×•×ª×¨×•×ª ×¢×œ×™×•× ×•×ª/×ª×—×ª×•× ×•×ª, ×•×©×‘×¨×™× ×›××• "44/0" ××• "0/44"
   - ×¨×§ ××¡×¤×¨×™× ××ª×•×š ×”×˜×‘×œ××•×ª ×¢×¦××Ÿ (×¢××•×“×ª "××¡×¤×¨ ×ª×ª ×—×œ×§×”") ×”× ×ª×§×¤×™×
5. ××¦× ××ª ×ª×ª ×”×—×œ×§×” ×”×¡×¤×¦×™×¤×™×ª ×©×”×“×•×— ××ª××§×“ ×‘×” (×‘×“×¨×š ×›×œ×œ ××•×“×’×© ××• ×‘×ª×—×™×œ×ª ×”××¡××š)

×—×©×•×‘: ×—×œ×¥ ××ª ×›×œ ×”××‘× ×™×, ×œ× ×¨×§ ××ª ×”×¨××©×•×Ÿ!

××•× ×—×™× ×¢×‘×¨×™×™× ×œ×—×™×¤×•×©:
- ×¦×• ×¨×™×©×•×, ×¦×• ×¨×™×©×•× ×‘×™×ª ××©×•×ª×£
- ×ª×™××•×¨ ×”×‘×™×ª, ×ª×™××•×¨ ×”××‘× ×”
- ××‘× ×”, ×‘× ×™×™×Ÿ, ×§×•××•×ª, ×§×•××”
- ×ª×ª ×—×œ×§×”, ×ª×ª×™ ×—×œ×§×•×ª, ×¡×”×´×› ×ª×ª×™ ×—×œ×§×•×ª
- ×›×ª×•×‘×ª, ×¨×—×•×‘, ×¢×™×¨

×”×—×–×¨ ×¨×§ JSON ×‘×¤×•×¨××˜ ×–×”:
{
  "buildings": [
    {
      "building_number": "××¡×¤×¨/××•×ª ××‘× ×”",
      "address": "×›×ª×•×‘×ª ××œ××”",
      "floors": "××¡×¤×¨ ×§×•××•×ª",
      "sub_plots_count": "×›××” ×ª×ª×™ ×—×œ×§×•×ª ×™×© ×‘××‘× ×” ×–×”",
      "confidence": 0.0-1.0
    }
  ],
  "total_sub_plots": "××¡×¤×¨ ×›×•×œ×œ ×ª×ª×™ ×—×œ×§×•×ª",
  "total_sub_plots_source": "×¡×”×´×› ××• ××¡×¤×¨ ×’×‘×•×” ×‘×™×•×ª×¨",
  "focus_sub_plot": "××¡×¤×¨ ×ª×ª ×”×—×œ×§×” ×©×”×“×•×— ×¢×•×¡×§ ×‘×”",
  "document_date": "×ª××¨×™×š ×”×•×¦××ª ×”×¦×•",
  "confidence_scores": {
    "buildings": 0.0-1.0,
    "total_sub_plots": 0.0-1.0,
    "focus_sub_plot": 0.0-1.0,
    "document_date": 0.0-1.0,
    "overall": 0.0-1.0
  }
}`;

    const userPrompt = `× ×ª×— ××ª ××¡××š ×¦×• ×¨×™×©×•× ×‘×™×ª ××©×•×ª×£ ×–×” ×•××¦× ××ª ×”××™×“×¢ ×”×‘×¡×™×¡×™ ×”××‘×•×§×©.

×”×ª××§×“ ×‘××¦×™××ª:
- ×›×œ ×”××‘× ×™× ×•×”×›×ª×•×‘×•×ª ××˜×‘×œ×ª ×ª×™××•×¨ ×”×‘×™×ª (×˜×‘×œ×” 1) - ×—×œ×¥ ××ª ×›×•×œ×!
- ×œ×›×œ ××‘× ×”: ××¡×¤×¨ ××‘× ×”, ×›×ª×•×‘×ª ××œ××”, ××¡×¤×¨ ×§×•××•×ª, ×•×›××” ×ª×ª×™ ×—×œ×§×•×ª ×™×© ×‘×•
- ×¡×”×´×› ×ª×ª×™ ×—×œ×§×•×ª ××”×©×“×” "×¡×”×´×› ×ª×ª×™ ×—×œ×§×•×ª" ×‘×˜×‘×œ×” 1, ××• ×”××¡×¤×¨ ×”×’×‘×•×” ×‘×™×•×ª×¨ ×‘×¢××•×“×ª "××¡×¤×¨ ×ª×ª ×—×œ×§×”"
- ×”×ª×¢×œ× ×××¡×¤×¨×™ ×¨×™×©×•× ×‘×›×•×ª×¨×•×ª/×ª×—×ª×™×•×ª ×”×“×£
- ×ª×ª ×”×—×œ×§×” ×”×¡×¤×¦×™×¤×™×ª ×©×”×“×•×— ×¢×•×¡×§ ×‘×”

×—×©×•×‘: ×× ×™×© 3 ××‘× ×™× ×‘×˜×‘×œ×” - ×—×œ×¥ ××ª ×©×œ×•×©×ª× ×¢× ×›×œ ×”×¤×¨×˜×™×!

×”×—×–×¨ ×¨×§ JSON ××•×‘× ×” ×›×¤×™ ×©× ×“×¨×©.`;

    return await this.callAnthropicAPI(systemPrompt, userPrompt, input, options, 4000);
  }

  /**
   * Step 2: Extract detailed fields based on structure analysis
   * @param {string|Buffer} input - Either markdown text or PDF file path
   * @param {Object} structureData - Results from step 1
   * @param {Object} options - Processing options
   * @returns {Promise<Object>} - Detailed field extraction
   */
  async extractDetailedFields(input, structureData, options = {}) {
    const systemPrompt = `××ª×” ××•××—×” ×œ×—×™×œ×•×¥ ×©×“×•×ª ××¤×•×¨×˜ ×××¡××›×™ ×¦×• ×¨×™×©×•× ×‘×™×ª ××©×•×ª×£.

×¢×œ ×‘×¡×™×¡ ×”× ×™×ª×•×— ×”××‘× ×™ ×©×§×™×‘×œ×ª, ×—×œ×¥ ××ª ×›×œ ×”×©×“×•×ª ×”× ×“×¨×©×™× ×‘×“×™×•×§:

1. ×ª×™××•×¨ ×”×‘×™×ª - ×¤×•×¨××˜ × ×“×¨×©:
   ×¢×¦×‘ ×›×š: "X ××‘× ×™×, Y ×§×•××•×ª ×œ××‘× ×” ×', Z ×§×•××•×ª ×œ××‘× ×” ×‘', ×›×ª×•×‘×ª: [×›×œ ×”×›×ª×•×‘×•×ª], [×¢×™×¨], ×‘×™×ª ××©×•×ª×£"
   ×›×œ×•×œ ××ª ×›×œ ×”××‘× ×™× ×¢× ×”×§×•××•×ª ×•×”×›×ª×•×‘×•×ª ×©×œ×”×

2. ×ª×™××•×¨ ×§×•××•×ª ××™×œ×•×œ×™:
   ×ª××¨ ×‘××™×œ×™× ××ª ×¡×¢×™×£ "×ª×™××•×¨ ×”×‘×™×ª" ××”××¡××š ×”××§×•×¨×™ - ×”×¢×ª×§ ××ª ×”×˜×§×¡×˜ ×”××“×•×™×§

3. ×›×œ ×”×›×ª×•×‘×•×ª ×•×›×œ ×”××‘× ×™×:
   ×¨×©×•× ××ª ×›×œ ×”×›×ª×•×‘×•×ª ××˜×‘×œ×ª ×ª×™××•×¨ ×”×‘×™×ª, ×œ× ×¨×§ ×”×¨××©×•× ×”
   ×œ×›×œ ××‘× ×” ×”×•×¡×£: ××¡×¤×¨ ××‘× ×”, ×›×ª×•×‘×ª, ×§×•××•×ª, ××¡×¤×¨ ×ª×ª×™ ×—×œ×§×•×ª

4. × ×ª×•× ×™ ×ª×ª ×”×—×œ×§×” ×”×¡×¤×¦×™×¤×™×ª:
   ××¦× ××ª ×ª×ª ×”×—×œ×§×” ${structureData.focus_sub_plot || '[×”××¡×¤×¨ ×©× ××¦×]'} ×•×—×œ×¥:
   - ×§×•××”
   - ×©×˜×— ×‘××´×¨
   - ×ª×™××•×¨ ××¤×•×¨×˜
   - ×”×¦××“×•×ª (×—× ×™×”, ××—×¡×Ÿ, ×’×™× ×” ×•×›×•')
   - ×—×œ×§×™× ×‘×¨×›×•×© ×”××©×•×ª×£

×”×—×–×¨ ×¨×§ JSON ×‘×¤×•×¨××˜ ×–×”:
{
  "building_description_formatted": "×ª×™××•×¨ ×‘×¤×•×¨××˜ ×”× ×“×¨×©",
  "building_description_original": "×”×¢×ª×§×” ××“×•×™×§×ª ×©×œ ×¡×¢×™×£ ×ª×™××•×¨ ×”×‘×™×ª",
  "all_addresses": ["×›×ª×•×‘×ª 1", "×›×ª×•×‘×ª 2", "..."],
  "all_buildings": [
    {
      "building_number": "××¡×¤×¨ ××‘× ×”",
      "address": "×›×ª×•×‘×ª ××œ××”",
      "floors": "××¡×¤×¨ ×§×•××•×ª",
      "sub_plots_count": "××¡×¤×¨ ×ª×ª×™ ×—×œ×§×•×ª"
    }
  ],
  "city": "×©× ×”×¢×™×¨",
  "order_issue_date": "×ª××¨×™×š ×”×•×¦××ª ×”×¦×•",
  "specific_sub_plot": {
    "number": "××¡×¤×¨ ×ª×ª ×”×—×œ×§×”",
    "floor": "×§×•××”",
    "area": "×©×˜×— ×‘××´×¨",
    "description": "×ª×™××•×¨",
    "attachments": ["×—× ×™×”", "××—×¡×Ÿ", "×’×™× ×”"],
    "shared_property_parts": "×—×œ×§×™× ×‘×¨×›×•×© ×”××©×•×ª×£"
  },
  "confidence_scores": {
    "building_description": 0.0-1.0,
    "all_addresses": 0.0-1.0,
    "all_buildings": 0.0-1.0,
    "specific_sub_plot": 0.0-1.0,
    "order_date": 0.0-1.0,
    "overall": 0.0-1.0
  }
}`;

    const userPrompt = `×¢×œ ×‘×¡×™×¡ ×”× ×™×ª×•×— ×”××‘× ×™ ×”×‘×:
${JSON.stringify(structureData, null, 2)}

×—×œ×¥ ××ª ×›×œ ×”×©×“×•×ª ×”××¤×•×¨×˜×™× ××”××¡××š.

×©×™× ×œ×‘ ×‘××™×•×—×“ ×œ:
- ×¢×™×¦×•×‘ ×ª×™××•×¨ ×”×‘×™×ª ×‘×¤×•×¨××˜ ×”××“×•×™×§ ×©× ×“×¨×©
- ×›×œ×™×œ×ª ×›×œ ×”×›×ª×•×‘×•×ª, ×œ× ×¨×§ ×”×¨××©×•× ×”
- ×—×™×œ×•×¥ ×›×œ ×”××‘× ×™× ×¢× ×›×œ ×”×¤×¨×˜×™× (××¡×¤×¨ ××‘× ×”, ×›×ª×•×‘×ª, ×§×•××•×ª, ××¡×¤×¨ ×ª×ª×™ ×—×œ×§×•×ª)
- ××¦×™××ª ×›×œ ×”× ×ª×•× ×™× ×©×œ ×ª×ª ×”×—×œ×§×” ×”××¡×¤×¨ ${structureData.focus_sub_plot || '[×œ× × ××¦×]'}
- ×”×¢×ª×§×” ××“×•×™×§×ª ×©×œ ×¡×¢×™×£ ×ª×™××•×¨ ×”×‘×™×ª ×”××§×•×¨×™

×—×©×•×‘: ×× ×™×© ${structureData.buildings?.length || '××¡×¤×¨'} ××‘× ×™× - ×—×œ×¥ ××ª ×›×•×œ×!

×”×—×–×¨ ×¨×§ JSON ××•×‘× ×”.`;

    return await this.callAnthropicAPI(systemPrompt, userPrompt, input, options, 6000);
  }

  /**
   * Step 3: Validate and format final results
   * @param {string|Buffer} input - Either markdown text or PDF file path
   * @param {Object} structureData - Results from step 1
   * @param {Object} detailedData - Results from step 2
   * @param {Object} options - Processing options
   * @returns {Promise<Object>} - Final validated results
   */
  async validateAndFormat(input, structureData, detailedData, options = {}) {
    const systemPrompt = `××ª×” ××•××—×” ×œ×•×™×“×•× ×•×¢×™×¦×•×‘ ×¡×•×¤×™ ×©×œ × ×ª×•× ×™ ×¦×• ×¨×™×©×•× ×‘×™×ª ××©×•×ª×£.

×©×œ×‘ ×•×™×“×•× ××—×¨×•×Ÿ: ×‘×“×•×§ ×©×›×œ ×”××™×“×¢ ××“×•×™×§ ×•××œ× ×œ×¤×™ ×”×“×¨×™×©×•×ª:

1. ×•×™×“×•× ×ª×™××•×¨ ×”×‘×™×ª:
   âœ“ ×”×× ×›×œ×•×œ ××¡×¤×¨ ×”××‘× ×™×?
   âœ“ ×”×× ×›×œ×•×œ ××¡×¤×¨ ×§×•××•×ª ×œ×›×œ ××‘× ×”?
   âœ“ ×”×× ×›×œ ×”×›×ª×•×‘×•×ª ×›×œ×•×œ×•×ª?
   âœ“ ×”×× ××¦×•×™×Ÿ "×‘×™×ª ××©×•×ª×£"?

2. ×•×™×“×•× ××¡×¤×¨ ×ª×ª×™ ×—×œ×§×•×ª:
   âœ“ ×”×× ×”××¡×¤×¨ ××’×™×¢ ×"×¡×”×´×› ×ª×ª×™ ×—×œ×§×•×ª" ×‘×˜×‘×œ×ª ×ª×™××•×¨ ×”×‘×™×ª?
   âœ“ ×× ×œ×, ×”×× ×–×” ×”××¡×¤×¨ ×”×’×‘×•×” ×‘×™×•×ª×¨ ×‘×¢××•×“×ª "××¡×¤×¨ ×ª×ª ×—×œ×§×”" ××˜×‘×œ××•×ª ×”×¤×™×¨×•×˜?
   âœ— ×•×•×“× ×©×”××¡×¤×¨ ×œ× ××’×™×¢ ×××¡×¤×¨×™ ×¨×™×©×•× ×‘×›×•×ª×¨×•×ª/×ª×—×ª×™×•×ª (×œ××©×œ "44/0" ××• "0/44")
   âœ— ×× ×”××¡×¤×¨ × ×¨××” ×›××• ×©×‘×¨ ××• ××¡×¤×¨ ×¨×™×©×•× - ×ª×§×Ÿ ×œ×¤×™ ×”×˜×‘×œ××•×ª ×‘×œ×‘×“

3. ×•×™×“×•× ×›×ª×•×‘×•×ª ×•××‘× ×™×:
   âœ“ ×”×× ×›×œ ×”×›×ª×•×‘×•×ª ××˜×‘×œ×ª ×ª×™××•×¨ ×”×‘×™×ª ×›×œ×•×œ×•×ª?
   âœ“ ×”×× ×›×œ ×”××‘× ×™× ××•×¤×™×¢×™× ×¢× ×›×œ ×”×¤×¨×˜×™× (××¡×¤×¨, ×›×ª×•×‘×ª, ×§×•××•×ª, ×ª×ª×™ ×—×œ×§×•×ª)?
   âœ“ ×× ×‘× ×™×ª×•×— ×”××‘× ×™ × ××¦××• 3 ××‘× ×™× - ×”×× ×›×•×œ× ××•×¤×™×¢×™×?

4. ×•×™×“×•× ×ª×ª ×”×—×œ×§×” ×”×¡×¤×¦×™×¤×™×ª:
   âœ“ ×”×× × ××¦××• ×›×œ ×”× ×ª×•× ×™× ×©×œ ×ª×ª ×”×—×œ×§×” ×©×”×“×•×— ×¢×•×¡×§ ×‘×”?

×ª×§×Ÿ ×›×œ ×—×¡×¨ ××• ×œ× ××“×•×™×§ ×•×ª×Ÿ ×ª×•×¦××” ×¡×•×¤×™×ª ××•×©×œ××ª.
×—×©×•×‘: ×•×•×“× ×©×›×œ ×”××‘× ×™× ×›×œ×•×œ×™× ×‘×ª×•×¦××” ×”×¡×•×¤×™×ª!

×”×—×–×¨ ×¨×§ JSON ×¡×•×¤×™ ×‘×¤×•×¨××˜ ×–×”:
{
  "order_issue_date": "×ª××¨×™×š ×”×•×¦××ª ×”×¦×•",
  "building_description": "×ª×™××•×¨ ×‘×¤×•×¨××˜: X ××‘× ×™×, Y ×§×•××•×ª...",
  "building_description_original": "×”×¢×ª×§×” ××“×•×™×§×ª ××”××¡××š",
  "building_floors": "××¡×¤×¨ ×§×•××•×ª ×›×•×œ×œ ××• ×œ××‘× ×” ×”×¨××©×™",
  "building_sub_plots_count": "××¡×¤×¨ ×ª×ª×™ ×—×œ×§×•×ª ×‘××‘× ×”",
  "building_address": "×›×ª×•×‘×ª ×¨××©×™×ª",
  "all_addresses": ["×›×œ ×”×›×ª×•×‘×•×ª"],
  "all_buildings": [
    {
      "building_number": "××¡×¤×¨ ××‘× ×”",
      "address": "×›×ª×•×‘×ª ××œ××”",
      "floors": "××¡×¤×¨ ×§×•××•×ª",
      "sub_plots_count": "××¡×¤×¨ ×ª×ª×™ ×—×œ×§×•×ª"
    }
  ],
  "city": "×¢×™×¨",
  "total_sub_plots": "×¡×”×´×› ×ª×ª×™ ×—×œ×§×•×ª",
  "total_sub_plots_source": "××§×•×¨ ×”××¡×¤×¨",
  "specific_sub_plot": {
    "number": "××¡×¤×¨",
    "floor": "×§×•××”",
    "area": "×©×˜×—",
    "description": "×ª×™××•×¨",
    "attachments": [],
    "shared_property_parts": "×—×œ×§×™×"
  },
  "confidence_scores": {
    "order_issue_date": 0.0-1.0,
    "building_description": 0.0-1.0,
    "building_floors": 0.0-1.0,
    "building_sub_plots_count": 0.0-1.0,
    "building_address": 0.0-1.0,
    "all_buildings": 0.0-1.0,
    "total_sub_plots": 0.0-1.0,
    "specific_sub_plot": 0.0-1.0,
    "overall": 0.0-1.0
  },
  "validation_notes": "×”×¢×¨×•×ª ×¢×œ ×ª×™×§×•× ×™× ×©×‘×•×¦×¢×•"
}`;

    const userPrompt = `×‘×“×•×§ ×•×ª×§×Ÿ ××ª ×”× ×ª×•× ×™× ×”×‘××™×:

× ×™×ª×•×— ××‘× ×™:
${JSON.stringify(structureData, null, 2)}

× ×ª×•× ×™× ××¤×•×¨×˜×™×:
${JSON.stringify(detailedData, null, 2)}

×•×•×“× ×©×”×ª×•×¦××” ×”×¡×•×¤×™×ª ×¢×•××“×ª ×‘×›×œ ×”×“×¨×™×©×•×ª ×•×ª×§×Ÿ ×›×œ ×‘×¢×™×” ×©××ª×” ××•×¦×.
×—×©×•×‘ ×‘××™×•×—×“: ×•×•×“× ×©×›×œ ×”××‘× ×™× (${structureData.buildings?.length || 'X'} ××‘× ×™×) ××•×¤×™×¢×™× ×‘-all_buildings ×¢× ×›×œ ×”×¤×¨×˜×™×!

×”×—×–×¨ JSON ×¡×•×¤×™ ××•×©×œ×.`;

    return await this.callAnthropicAPI(systemPrompt, userPrompt, input, options, 8000);
  }

  /**
   * Helper method to call Anthropic API
   */
  async callAnthropicAPI(systemPrompt, userPrompt, input, options, maxTokens) {
    let messageContent;
    let pdfBuffer = null;

    // Handle PDF file path input
    if (options.isPdf && typeof input === 'string') {
      pdfBuffer = fs.readFileSync(input);
    } else if (options.useVision && typeof input === 'string') {
      pdfBuffer = fs.readFileSync(input);
    } else if (Buffer.isBuffer(input)) {
      pdfBuffer = input;
    }

    if (pdfBuffer) {
      messageContent = [
        {
          type: "text",
          text: userPrompt
        },
        {
          type: "document",
          source: {
            type: "base64",
            media_type: "application/pdf",
            data: pdfBuffer.toString('base64')
          }
        }
      ];
    } else {
      messageContent = userPrompt + (typeof input === 'string' ? `\n\n××¡××š:\n${input}` : '');
    }

    const message = await this.client.messages.create({
      model: this.model,
      max_tokens: maxTokens,
      temperature: 0,
      system: systemPrompt,
      messages: [
        {
          role: "user",
          content: pdfBuffer ? messageContent : messageContent
        }
      ]
    });

    const content = message.content[0].text;

    // Parse JSON with error handling
    let extractedData;
    try {
      extractedData = JSON.parse(content);
    } catch (parseError) {
      const jsonMatch = content.match(/\{[\s\S]*\}/);
      if (jsonMatch) {
        let jsonText = jsonMatch[0]
          .replace(/,(\s*[}\]])/g, '$1')
          .replace(/([}\]]),(\s*[}\]])/g, '$1$2')
          .replace(/,(\s*,)/g, ',')
          .replace(/\.\.\./g, '')
          .replace(/\n/g, ' ')
          .replace(/\r/g, '')
          .replace(/\t/g, ' ')
          .replace(/\s+/g, ' ')
          .replace(/,(\s*[}\]])/g, '$1')
          .trim();

        extractedData = JSON.parse(jsonText);
      } else {
        throw new Error('No valid JSON found in response');
      }
    }

    return {
      data: extractedData,
      usage: message.usage,
      rawResponse: content
    };
  }

  /**
   * Extract all fields using 3-step Hebrew prompt approach
   * @param {string|Buffer} input - Either markdown text or PDF file path
   * @param {Object} options - Processing options {useVision: boolean}
   * @returns {Promise<Object>} - Structured extraction results
   */
  async extractAllFields(input, options = {}) {
    const startTime = Date.now();
    console.log('ğŸ”„ Starting 3-step Hebrew extraction process...');

    try {
      // Step 1: Extract document structure
      console.log('ğŸ“‹ Step 1: Analyzing document structure...');
      const step1Result = await this.extractDocumentStructure(input, options);
      const structureData = step1Result.data;
      console.log(`âœ… Step 1 completed. Found ${structureData.buildings?.length || 0} buildings, focus sub-plot: ${structureData.focus_sub_plot || 'not found'}`);

      // Step 2: Extract detailed fields
      console.log('ğŸ” Step 2: Extracting detailed fields...');
      const step2Result = await this.extractDetailedFields(input, structureData, options);
      const detailedData = step2Result.data;
      console.log(`âœ… Step 2 completed. Addresses found: ${detailedData.all_addresses?.length || 0}`);

      // Step 3: Validate and format
      console.log('âœ“ Step 3: Validating and formatting final results...');
      const step3Result = await this.validateAndFormat(input, structureData, detailedData, options);
      const finalData = step3Result.data;
      console.log('âœ… Step 3 completed. Final validation done.');

      // Calculate total cost and tokens
      const totalTokens = (step1Result.usage?.total_tokens || 0) +
                         (step2Result.usage?.total_tokens || 0) +
                         (step3Result.usage?.total_tokens || 0);
      const totalCost = this.estimateCost(totalTokens);

      // Structure the result to match the expected format
      const result = {
        order_issue_date: {
          value: finalData.order_issue_date || null,
          confidence: (finalData.confidence_scores?.order_issue_date || 0) * 100,
          context: 'Step 3 validation',
          pattern: '3_step_hebrew_extraction'
        },

        building_description: {
          value: finalData.building_description || null,
          confidence: (finalData.confidence_scores?.building_description || 0) * 100,
          context: finalData.building_description_original || 'Step 2 extraction',
          pattern: '3_step_hebrew_extraction'
        },

        building_floors: {
          value: finalData.building_floors || null,
          confidence: (finalData.confidence_scores?.building_floors || 0) * 100,
          context: 'From building structure analysis',
          pattern: '3_step_hebrew_extraction'
        },

        building_sub_plots_count: {
          value: finalData.building_sub_plots_count || null,
          confidence: (finalData.confidence_scores?.building_sub_plots_count || 0) * 100,
          context: 'From building analysis',
          pattern: '3_step_hebrew_extraction'
        },

        building_address: {
          value: finalData.building_address || null,
          confidence: (finalData.confidence_scores?.building_address || 0) * 100,
          context: `All addresses: ${(finalData.all_addresses || []).join(', ')}`,
          pattern: '3_step_hebrew_extraction'
        },

        total_sub_plots: {
          value: finalData.total_sub_plots || null,
          confidence: (finalData.confidence_scores?.total_sub_plots || 0) * 100,
          context: finalData.total_sub_plots_source || 'Step 1 analysis',
          pattern: '3_step_hebrew_extraction'
        },

        buildings_info: {
          value: finalData.all_buildings || structureData.buildings || [],
          confidence: (finalData.confidence_scores?.all_buildings || structureData.confidence_scores?.buildings || 0) * 100,
          context: 'Complete buildings list from step 3 validation',
          pattern: '3_step_hebrew_extraction',
          count: (finalData.all_buildings || structureData.buildings || []).length
        },

        specific_sub_plot: {
          value: finalData.specific_sub_plot || null,
          confidence: (finalData.confidence_scores?.specific_sub_plot || 0) * 100,
          context: `Focus sub-plot: ${structureData.focus_sub_plot || 'not identified'}`,
          pattern: '3_step_hebrew_extraction'
        },

        // Additional fields from 3-step process
        all_addresses: {
          value: finalData.all_addresses || [],
          confidence: (finalData.confidence_scores?.building_address || 0) * 100,
          context: 'Complete address list from building table',
          pattern: '3_step_hebrew_extraction',
          count: finalData.all_addresses?.length || 0
        },

        city: {
          value: finalData.city || null,
          confidence: (finalData.confidence_scores?.building_address || 0) * 100,
          context: 'Extracted from addresses',
          pattern: '3_step_hebrew_extraction'
        },

        // Metadata
        overallConfidence: (finalData.confidence_scores?.overall || 0) * 100,
        processingTime: Date.now() - startTime,
        method: '3_step_hebrew_anthropic',
        model: this.model,
        tokensUsed: totalTokens,
        cost: totalCost,
        stepsCompleted: 3,
        validationNotes: finalData.validation_notes || 'No validation notes',
        rawResponses: {
          step1: step1Result.rawResponse.substring(0, 200) + '...',
          step2: step2Result.rawResponse.substring(0, 200) + '...',
          step3: step3Result.rawResponse.substring(0, 200) + '...'
        }
      };

      console.log(`ğŸ‰ 3-step extraction completed successfully!`);
      console.log(`â±ï¸  Total time: ${result.processingTime}ms`);
      console.log(`ğŸ”— Total tokens: ${totalTokens}`);
      console.log(`ğŸ’° Estimated cost: $${totalCost.toFixed(4)}`);
      console.log(`ğŸ“Š Overall confidence: ${result.overallConfidence.toFixed(1)}%`);
      console.log(`ğŸ¢ Buildings: ${result.buildings_info?.count || 0}`);

      return result;

    } catch (error) {
      console.error('âŒ 3-step extraction failed:', error.message);
      throw new Error(`3-step Hebrew extraction failed: ${error.message}`);
    }
  }

  /**
   * Extract a specific field with focused prompting
   * @param {string} markdownText - Document text
   * @param {string} fieldName - Specific field to extract
   * @returns {Promise<Object>} - Field extraction result
   */
  async extractSpecificField(markdownText, fieldName) {
    const fieldPrompts = {
      order_issue_date: 'Extract the order issue date (×ª××¨×™×š ×”×•×¦××ª ×”×¦×•) when the shared building order was issued',
      building_description: 'Extract the building description (×ª×™××•×¨ ×”××‘× ×”) - what type of building it is',
      building_floors: 'Extract the number of floors (××¡×¤×¨ ×§×•××•×ª) in the building',
      building_sub_plots_count: 'Extract the number of sub-plots/units (××¡×¤×¨ ×ª×ª×™ ×—×œ×§×•×ª) in this building',
      building_address: 'Extract the complete building address (×›×ª×•×‘×ª ×”××‘× ×”)',
      total_sub_plots: 'Extract the total number of sub-plots (×¡×”"×› ×ª×ª×™ ×—×œ×§×•×ª) in the entire project',
      sub_plots: 'Extract all individual sub-plot details (×¤×™×¨×•×˜ ×ª×ª×™ ×”×—×œ×§×•×ª) including floor, area, description'
    };

    const prompt = `Extract ONLY the ${fieldName} from this Hebrew shared building order document:

${markdownText}

Task: ${fieldPrompts[fieldName]}

Return JSON format:
{
  "${fieldName}": {
    "value": extracted_value,
    "confidence": confidence_score_0_to_1,
    "context": "exact_text_where_found"
  }
}`;

    try {
      const message = await this.client.messages.create({
        model: this.model,
        max_tokens: 1500,
        temperature: 0,
        messages: [
          {
            role: "user",
            content: prompt
          }
        ]
      });

      const content = message.content[0].text;
      const jsonMatch = content.match(/\{[\s\S]*\}/);
      
      if (jsonMatch) {
        let jsonText = jsonMatch[0];
        
        // Clean common JSON formatting issues aggressively
        jsonText = jsonText
          .replace(/,(\s*[}\]])/g, '$1')  // Remove trailing commas
          .replace(/([}\]]),(\s*[}\]])/g, '$1$2')  // Remove trailing commas before closing brackets
          .replace(/,(\s*,)/g, ',')  // Remove duplicate commas
          .replace(/\.\.\./g, '')    // Remove ellipsis that might break JSON
          .replace(/\n/g, ' ')  // Replace newlines with spaces
          .replace(/\r/g, '')   // Remove carriage returns
          .replace(/\t/g, ' ')  // Replace tabs with spaces
          .replace(/\s+/g, ' ') // Normalize multiple spaces
          .replace(/,(\s*[}\]])/g, '$1')  // Remove trailing commas again after cleanup
          .trim();
        
        // If JSON is too long and likely causing issues, truncate sub_plots array
        if (jsonText.length > 20000) {
          console.warn('âš ï¸  JSON response very long, truncating sub_plots array to prevent parsing errors');
          jsonText = jsonText.replace(/"sub_plots":\s*\[[^\]]*\]/g, '"sub_plots": [{"truncated": true}]');
        }
        
        try {
          return JSON.parse(jsonText);
        } catch (parseError) {
          console.error('JSON parse error in extractSingleField:', parseError.message);
          console.error('Problematic JSON:', jsonText.substring(0, 300) + '...');
          throw new Error(`JSON parsing failed: ${parseError.message}`);
        }
      } else {
        throw new Error('No JSON found in response');
      }
    } catch (error) {
      throw new Error(`Failed to extract ${fieldName}: ${error.message}`);
    }
  }

  /**
   * Estimate API cost based on token usage
   * @param {number} tokens - Total tokens used
   * @returns {number} - Estimated cost in USD
   */
  estimateCost(tokens) {
    // Claude Opus pricing: $15 per 1M input tokens, $75 per 1M output tokens
    // Rough estimate assuming 70% input, 30% output
    const inputTokens = Math.floor(tokens * 0.7);
    const outputTokens = Math.floor(tokens * 0.3);
    
    return ((inputTokens * 15) + (outputTokens * 75)) / 1000000;
  }
}

module.exports = {
  SharedBuildingAIExtractor
};
